{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [12.0, 8.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/Auto1-DS-TestData.csv'\n",
    "random_state = 0\n",
    "test_size = 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '?' is used in the file for missing values \n",
    "data = pd.read_csv(data_path, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing value in price column: 4\n"
     ]
    }
   ],
   "source": [
    "# Check number of missing values in the column we are trying to predict (price)\n",
    "print('Number of missing value in price column: {}'.format(data.price.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the price column\n",
    "data = data.dropna(subset=[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split data into model selection and test. We will only use test data at the end, to report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, te = train_test_split(data, test_size = test_size, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep only numeric columns for now, to keep things simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check number of nans in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling             0\n",
       "normalized-losses    20\n",
       "wheel-base            0\n",
       "length                0\n",
       "width                 0\n",
       "height                0\n",
       "curb-weight           0\n",
       "engine-size           0\n",
       "bore                  2\n",
       "stroke                2\n",
       "compression-ratio     0\n",
       "horsepower            2\n",
       "peak-rpm              2\n",
       "city-mpg              0\n",
       "highway-mpg           0\n",
       "price                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.apply(lambda c: c.isnull().sum(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column normalized-losses has a somewhat large number of nans. It's not extremely large though, so we won't discard that column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to approximate the function that maps _feature_ vectors (vectors $v$ drawn from the 14 dimensional space where $v_1$ is the symboling value, $v_2$ is the normalized losses value, etc.) to prices (the _target_ variable).\n",
    "\n",
    "Price is a continuos variable, so this is a _regression_ problem. \n",
    "\n",
    "Our learning algorithm will try to fit a certain model to the training data. That is, based on the relation between the features and the target on the training instances, it will try to adjust certain model parameters so the model captures that relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model will be a __Ridge__ regressor. This is a very basic model, that simply adds a regularization term to classic linear regression. It is a _linear_ model. This means that if the underlying function we are trying to approximate (the function that maps features to prices) is highly non linear (i.e price does not vary linearly with the features), the approximation might not be good. However, this models are simple to train, and it is usually a good idea to try them first to get an initial baseline. Further, in many real scenarios where many more features might be available, assuming linear relations between the features and the target is more than reasonable.\n",
    "\n",
    "For the training algorithm to work, training features must be free of nans. We will impute missing values in a given column with the median for that column. \n",
    "\n",
    "Also, linear models tend to work much better when the different features are in the same scale (If column A contains values an order of magnitued larger than values of column B, changes in B might seem irrelevant to the linear function $w_A * A + w_B * B$). We therefore satandarize each column (that is, we substract the column mean and divide by the column standard deviation) \n",
    "\n",
    "We assemble all three steps (imputing, scaling and the ridge regressor) in a pipeline. This is extremly useful for organizing the train-validation-test regime, as we will se below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('imputer', Imputer(strategy='median')), ('scaler', StandardScaler()), ('rgs', Ridge())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every machine learning model has a certain set of hyper-parameters that need to be chosen to univocally define the model. \n",
    "\n",
    "Ridge has only one hyper-parameter that is relevant to us for this problem: the weight of the regularization term. Regularization is a topic in its own. Let's just say that regularization controls how well the trained model will fit the trained data. Less regularization will result in models that fit the training data \"too well\", possibly capturing artifacts do to noise or sampling (training in data is just a sample of underlying distributions that we are trying to model). Such _overfitted_ models won't _generalize_ well (they won't behave as the underlying mapping function on data not present in the training set)\n",
    "\n",
    "To choose the right value of the reguarization weight, we perform a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range = np.array([10, 1, 0.1, 0.01, 0.001, 0.0001, 0])\n",
    "grid = {'rgs__alpha':alpha_range}\n",
    "ridge_gs = GridSearchCV(pipeline, grid, scoring='neg_mean_absolute_error', cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling $fit$ on the grid search will compute a certain performance measure for each combination of values in the arrays in $grid$ (i.e., for each point in the grid). The combination of values that give the best performance will be chosen as the optimal hyper-parameter set. \n",
    "\n",
    "How is this performance measure computed for each point in the grid? By n-fold cross-validation. Specifically, the training set is splitted into as many (equally sized) parts as stated by the variable _cv_ above and, for each possible combination of _cv_ - 1 parts, the pipeline is trained on the set made of those _cv_ - 1 parts and tested on the remaining part. Testing involves using the trained pipeline to _predict_ a value for eaach test vector on the test part. After obtaining a prediction for each vector, a score is computed for the test part by comparing the predictions and the true values (in our case, the actual value in the $price$ column). The performance for a given grid point is obtained by averaging the score of the different test parts. Note that the whole pipeline (imputer, scaler and regressor) is trained each time on the selected _cv_ - 1 parts and tested on the remaining part. That is, not only the parameters of the Ridge regressor are adjusted during each training step: the median (for the imputer) and the mean and standard deviation (for the scaler) are also computed, and then applied to preprocess the test part before applying the trained regressor. Sklearn framework makes this plumbing really easy. \n",
    "\n",
    "The specific scoring function is indicated by the parameter $scoring$. In this case, I have chosen the _mean absolute error_ or _MAE_. This is just the average over the test part of the absolute differences between the prediction and the true value. We have chosen MAE because it shows errors in the same units as the price (as opposed to, for example, the _coefficient of determination_): we wanted to see the error in money units. Among the alternatives, we could have also used (for example) _mean suqared error_ (_MSE_). _MSE_ tends to give higher weight to large errors (because of the squared differences), and its interpretation is more involved than that of _MAE_. In any case, most of these scoring functions would probably give similar results in terms of model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rgs', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'rgs__alpha': array([1.e+01, 1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 0.e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_gs.fit(tr.drop(['price'], axis=1), tr.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, being a linear model, the Ridge regressor might be limited in terms of its ability to capture more complex (non-linear) relations between the different features and the price. Therefore, let's try an example of a non-linear model. \n",
    "\n",
    "We have chosen the __Gradient Boosting__ regressor. As it name indicates, this is an example of a _boosting_ method. This means that training this model consists in iteratively training weak learners, each newly trained learner focused in instances that previously trained learners found difficult. In a nutshell, a gradient boosting regressor trains regression trees, and each new tree is trained on the previous trees errors, effectively yielding a steepest descent algorithm on the gradient of the squared loss of the final classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('imputer', Imputer(strategy='median')), \n",
    "                     ('rgs', GradientBoostingRegressor(n_estimators=3000, random_state=random_state))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this time our pipeline does not include a scale step. This is because gradient boosting is based on trees, which are not affected by features scales (as opposed to a linear function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the ridge regressor, gradient boosting has many more hyper-parameters that need to be tuned. \n",
    "\n",
    "Therefore, instead of doing an exhaustive grid search, this time we will do a randomized search. For each parameter, we specify either a list of possible values or distribution to sample from. Further, we specify a number of grid points to try. Calling $fit$ will try that number of points by sampling from the different distributios/lists. In this way, we can get a relatively (it might take a couple of minutes) fast search while still exploring representaive regions of the space of hyperparameters. Also, note that we set n_jobs = -1, to use every processor available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_vals =  [0.1, 0.05, 0.02, 0.01]\n",
    "max_depth_dist = sp_randint(4, 6)\n",
    "min_samples_leaf_dist = sp_randint(3, 17)\n",
    "max_features_vals = [1.0, 0.3, 0.1]\n",
    "grid = {'rgs__learning_rate': learning_rate_vals, \n",
    "        'rgs__max_depth': max_depth_dist, \n",
    "        'rgs__min_samples_leaf': min_samples_leaf_dist, \n",
    "        'rgs__max_features': max_features_vals}\n",
    "\n",
    "# run randomized search\n",
    "n_points = 20\n",
    "gb_gs = RandomizedSearchCV(pipeline, param_distributions= grid, \n",
    "                           n_iter= n_points, \n",
    "                           random_state = random_state,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('rgs', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impur...ors=3000, presort='auto', random_state=0,\n",
       "             subsample=1.0, verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'rgs__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fb1cc72ccd0>, 'rgs__max_features': [1.0, 0.3, 0.1], 'rgs__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fb1cc72cc90>, 'rgs__learning_rate': [0.1, 0.05, 0.02, 0.01]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_absolute_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.fit(tr.drop(['price'], axis=1), tr.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try including some categorical features now (we did not take them into account for the previous models). Let's see if it helps improving our ridge regressor performance. In order to use categorical features with this kind of model, we need to _one hot encode_ them. That is, each categorical feature $f$ needs to be represented as $n_f$ different binary features, where $n_f$ is the number of possible values that $f$ can take. Each possible value of $f$ is assigned a different feature among the $n_f$. Given a specific feature vector $x$ with $x_f = v$, one hot encoding $x$ gives as a result a new vector for which $x_f$ is replaced by $n_f$ binary features. Among those features, only the one corresponding to $v$ is set to one (the _hot_ one). The rest of the features are set to zero. \n",
    "\n",
    "Pandas function _get__dummies()_ comes in very handy for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look for example at the categorical feature _fuel-system_. Before one hot encoding, our dataset contained a single column that could take 8 different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpfi    92\n",
       "2bbl    64\n",
       "idi     20\n",
       "1bbl    11\n",
       "spdi     9\n",
       "4bbl     3\n",
       "spfi     1\n",
       "mfi      1\n",
       "Name: fuel-system, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['fuel-system'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After encoding, _fuel-system_ has been replaced by 8 binary columns, one per possible value _fuel-system_ could take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel-system_1bbl</th>\n",
       "      <th>fuel-system_2bbl</th>\n",
       "      <th>fuel-system_4bbl</th>\n",
       "      <th>fuel-system_idi</th>\n",
       "      <th>fuel-system_mfi</th>\n",
       "      <th>fuel-system_mpfi</th>\n",
       "      <th>fuel-system_spdi</th>\n",
       "      <th>fuel-system_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fuel-system_1bbl  fuel-system_2bbl  fuel-system_4bbl  fuel-system_idi  \\\n",
       "0                 0                 0                 0                0   \n",
       "1                 0                 0                 0                0   \n",
       "2                 0                 0                 0                0   \n",
       "3                 0                 0                 0                0   \n",
       "4                 0                 0                 0                0   \n",
       "5                 0                 0                 0                0   \n",
       "6                 0                 0                 0                0   \n",
       "7                 0                 0                 0                0   \n",
       "\n",
       "   fuel-system_mfi  fuel-system_mpfi  fuel-system_spdi  fuel-system_spfi  \n",
       "0                0                 1                 0                 0  \n",
       "1                0                 1                 0                 0  \n",
       "2                0                 1                 0                 0  \n",
       "3                0                 1                 0                 0  \n",
       "4                0                 1                 0                 0  \n",
       "5                0                 1                 0                 0  \n",
       "6                0                 1                 0                 0  \n",
       "7                0                 1                 0                 0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat[[col for col in data_cat if col.startswith('fuel-system')]].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our data again (using the same random_state to get the same partition as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, te = train_test_split(data_cat, test_size = test_size, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tune the same pipeline as we did above for the ridge regressor, only this time we include categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('imputer', Imputer(strategy='median')), ('scaler', StandardScaler()), ('rgs', Ridge())])\n",
    "alpha_range = np.array([10, 1, 0.1, 0.01, 0.001, 0.0001, 0])\n",
    "grid = {'rgs__alpha':alpha_range}\n",
    "ridge_cat_gs = GridSearchCV(pipeline, grid, scoring='neg_mean_absolute_error', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rgs', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'rgs__alpha': array([1.e+01, 1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 0.e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cat_gs.fit(tr.drop(['price'], axis=1), tr.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the performance of the different experiments. For each of the three experiments, we add the average score and the score standard deviation to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = pd.DataFrame(columns=['Experiment', 'MAE mean', 'MAE std'])\n",
    "gs_results = [('Ridge num', ridge_gs), ('Gradient boosting', gb_gs), ('Ridge cat', ridge_cat_gs)]\n",
    "for r in gs_results:\n",
    "    std_score = r[1].cv_results_['std_test_score'][r[1].cv_results_['mean_test_score'] == r[1].best_score_][0]\n",
    "    mean_score = -r[1].best_score_\n",
    "    performances = performances.append({'Experiment':r[0], 'MAE mean':mean_score, 'MAE std':std_score}, \n",
    "                                       ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>MAE mean</th>\n",
       "      <th>MAE std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient boosting</td>\n",
       "      <td>1468.580398</td>\n",
       "      <td>293.804816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge cat</td>\n",
       "      <td>1637.133569</td>\n",
       "      <td>197.356747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge num</td>\n",
       "      <td>2248.668911</td>\n",
       "      <td>329.195607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Experiment     MAE mean     MAE std\n",
       "1  Gradient boosting  1468.580398  293.804816\n",
       "2          Ridge cat  1637.133569  197.356747\n",
       "0          Ridge num  2248.668911  329.195607"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances.sort_values(by='MAE mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that gradient boosting using only numerical features achieves the best mean MAE. However, the ridge regressor on both numerical and categorical features achieves a somewhat similar mean MAE, and better MAE standard deviation. Ridge regressor trained just on the numerical features is the worse, both in terms of MAE mean and MAE std. \n",
    "\n",
    "Which of _gradient boosting_ and _ridge cat_ should we choose?. We choose the ridge regressor, given its simplicity, reasonable MAE mean and lower variance, but it is not easy to get a definite answer here. \n",
    "\n",
    "Let's get an estimate of the generalization error for _ridge cat_, by computing MAE mean on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regressor mean MAE on the test set: 2359.02668398\n"
     ]
    }
   ],
   "source": [
    "print('Ridge regressor mean MAE on the test set: {}'.format(\n",
    "    -ridge_cat_gs.score(te.drop(['price'], axis=1), te.price)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of things that would be interesting to try.\n",
    "\n",
    "1) Traim gradient boosting with both numerical and categorical features\n",
    "\n",
    "2) Perform bootstrapping or nested cross-validation to get confident intervals for the estimated generalization error.\n",
    "\n",
    "3) Analyze feature importance for the different models. Are there any key features? Do they provide useful insights into the use case?\n",
    "\n",
    "4) Extend these features with an external dataset and check for improvements. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
